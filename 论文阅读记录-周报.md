### MaskFormer (NIPS 2021)

**Per-Pixel Classification is Not All You Need for Semantic Segmentation**

**why**

出发点：以统一的方式（掩码分类）解决语义级和实例级分割任务

以前的：将语义分割制定为逐像素分类任务，而实例级分割则使用掩码分类来处理

**what**

1，提出了一个简单的MaskFormer方法，可以无缝地将任何现有的逐像素分类模型转换为掩码分类。新模型以统一的方式解决语义级和实例级分割任务:不需要更改模型、损失和训练过程。

2，设计了一个简单的推理策略，将MaskFormer输出混合到任务相关的预测格式中。

**how**

![image-20230808092836929](论文阅读记录-周报.assets/image-20230808092836929.png)

**总体架构**：Maskformer包含三个模块:1)像素级模块，用于提取用于生成二值掩码预测的逐像素嵌入;2)transformer模块，其中transformer解码器层计算N个每段嵌入;3)分割模块，从这些嵌入中生成预测，即N个概率掩码对 $\{(p_i,m_i)\}_{i=1}^N$

**技术细节**

**像素级模块**包括提取特征的backbone，以及用于上下样的像素解码器。任何基于逐像素分类的分割模型都适合像素级模块设计，MaskFormer无缝地将这样的模型转换为掩码分类。

**Transformer模块**使用标准Transformer解码器从图像特征$\mathcal{F}$和N个可学习的位置嵌入(即查询)中计算其输出，从而编码MaskFormer预测的每个段的全局信息。

**分割模块**在每个段嵌入$\mathcal{Q}$的基础上应用线性分类器，然后进行softmax激活，以产生每个段的类概率预测，如果嵌入不对应任何区域，分类器会预测一个额外的“无对象”类别(∅)。对于掩码预测，具有2个隐藏层的多层感知器(MLP)将段嵌入Q转换为N个掩码嵌入。最后，通过像素级模块计算的逐像素嵌入与掩码嵌入之间的点积得到每个二值掩码预测。

训练过程中，$L_{mask-cls}$损失结合了交叉熵分类损失和每个预测段的二值掩码损失$L_{mask}$。$L_{mask}$采用focal loss和dice loss的结合，并基于二部匹配从而匹配真值。

![image-20230808102326363](论文阅读记录-周报.assets/image-20230808102326363.png)

**掩码分类推理**：一般推理，通过$argmax_{i:c_i \neq \phi}p_i(c_i)\cdot m_i[h,w]$将每个像素[h, w]分配给N个预测概率掩码对中的一个，将图像分割成若干段。对于每个概率掩码对i，$c_i$是最有可能的类标签。直观地，只有当最可能的类概率pi(ci)和掩码预测概率mi [h, w]都很高时，该过程才会将位置[h, w]的像素分配给概率掩码对i。分配给相同概率掩码对i的像素形成一个段，其中每个像素用$c_i$标记。

对于语义分割，将具有相同类别标签的片段进行合并;而对于实例级分割任务，概率掩码对的索引I有助于区分同一类的不同实例。

**conclusion**

**优点**：基于掩码分类实现了通用语义分割

**缺点**：

1，掩码查询的设计。最优的query个数跟类别数没有关系，貌似跟平均每张图片里出现的类别数相关（不是相等的关系！）。不同的query个数对结果的影响挺大。此外，每个查询的唯一类别的数量并不遵循统一的分布（有的多有的少），查询也没有明确的模式（有些查询捕获具有相似语义或形状的类别，有些捕获完全不同的类别）如何能根据一些先验信息去设计query是个挺有意思的研究方向。

2，难以训练，显存占用大，需要更多的训练时间

### Mask2Former (CVPR 2022)

**Masked-attention Mask Transformer for Universal Image Segmentation**

**why**

出发点：提出一种能够处理任何图像分割任务(全景、实例或语义)的新架构

以前的：为每个任务设计专门的体系结构

**what**

1，提出了一种通用的图像分割架构Mask2Former，它在不同的分割任务中优于专门的架构，同时仍然易于在每个任务上进行训练。

2，构建了一个简单的元架构，由主干特征提取器、像素解码器和Transformer解码器组成。提出关键的改进建议

1）在Transformer解码器中使用掩码注意力，它将注意力限制在以预测片段为中心的局部特征上，这些特征可以是对象或区域，具体取决于分组的特定语义

2）使用多尺度高分辨率特征，帮助模型分割小物体/区域

3）提出了切换自关注和交叉关注的顺序、使查询特征可学习、去除dropout等优化改进，在不增加额外计算的情况下提高性能

4）在不影响性能的情况下，通过对少量随机采样点计算掩码损失，节省了3倍的训练内存

**how**

<img src="论文阅读记录-周报.assets/image-20230808151151939.png" alt="image-20230808151151939" style="zoom:80%;" />

**元架构**：一个简单的元结构将由三个组件组成。主干，从图像中提取低分辨率特征。像素解码器，它从主干的输出逐渐上采样低分辨率特征，以生成高分辨率的逐像素嵌入。Transformer解码器，它操作图像特征来处理对象查询。最终的二进制掩码预测是用对象查询从逐像素嵌入中解码出来的。这种元架构的一个成功实例是MaskFormer

**掩码注意力**：最近研究表明，基于transformer的模型的缓慢收敛是由于交叉注意层中的全局上下文，因为交叉注意需要许多次训练才能学会关注局部目标区域。本文假设局部特征足以更新查询特征，并且可以通过自关注收集上下文信息。为此，提出了掩码注意，这是交叉注意的一种变体，它只关注每个查询的预测掩码的前景区域

<img src="论文阅读记录-周报.assets/image-20230808151720652.png" alt="image-20230808151720652"  />

![image-20230808151746675](论文阅读记录-周报.assets/image-20230808151746675.png)

![image-20230808151817669](论文阅读记录-周报.assets/image-20230808151817669.png)

$\mathcal{M}_{l-1}$即为第l-1层的注意力掩码，$M_{l-1}$是前一层解码器输出的特征做二值化之后的结果。 Q为查询特征，K和V为图像特征。即相当于根据上一层的注意力掩码获得前景区域，只计算前景区域的注意力交互。

**高分辨率特征**：使用由低分辨率和高分辨率特征组成的特征金字塔（分辨率分别为原始图像的1/32、1/16和1/8），并一次向一个Transformer解码器层提供一个分辨率的特征。对于每个分辨率，添加一个正弦位置嵌入向量和可学习的尺度级嵌入向量。对相应的Transformer解码器层从最低分辨率到最高分辨率使用它们，并重复这个3层变压器解码器L次。（提高模型对于小物体分割的性能，并控制计算量的增加）

**优化改进**：

1）切换自关注和交叉关注的顺序。第一个自注意层的查询特征是图像独立的，没有来自图像的信号，因此应用自注意不太可能丰富信息。

2）使查询特征(X0)也是可学习的(仍然保留可学习的查询位置嵌入)，并且在在Transformer解码器中预测掩码(M0)之前，直接监督可学习的查询特征。我们发现这些可学习的查询特征的功能类似于区域建议网络[43]，并且能够生成掩码建议。（之前的查询特征(X0)在输入Transformer解码器之前被初始化为零，并与可学习的位置嵌入相关联）

3）发现dropout是不必要的，通常会降低性能。因此，完全消除了解码器中的dropout。

**conclusion**

**优点**：基于掩码注意力加速模型收敛，以及其他的一些优化策略，来改进maskformer

**缺点**：貌似也是玄学设计query的数量和模式。能否添加额外的监督，比如使得query互相正交，从而提升模型表现?

### CAC（AAAI 2023 oral）

**Learning Context-Aware Classifier for Semantic Segmentation**

**why**

出发点：通过学习上下文感知分类器来利用额外的上下文提示, 适当地适应不同的潜在分布

以前的：固定的分类器，可能无法很好地处理测试过程中不同的特征分布

**what**

1，提出学习上下文感知分类器，其内容根据不同的样本而变化，而不是通常使用的静态分类器

2，为了使上下文感知分类器学习易于处理，设计了熵感知KL损失来减轻信息不平衡带来的不利影响。

3，该方法很容易插入到其他现有的分割模型中，在效率上几乎没有补偿的情况下取得了相当大的改进

**how**

![image-20230808193211083](论文阅读记录-周报.assets/image-20230808193211083.png)

一个通用的深度模型可以看作是由特征生成器和分类器组成。特征生成器将图像投影为高维特征而分类器对不同位置上的像素进行分类预测。即分类器应该充当特征描述符，其权重用作高维特征空间中的决策边界，描述特征分布并做出判断，即像素预测。然而，用于语义分割的图像通常具有不同的上下文提示，使用所有测试样本共享的通用特征描述符(即分类器)可能不是解析单个图像局部细节的最佳选择。

因此，作者设计了一个对于不同样本上下文感知的分类器，在提高性能的同时保持特征生成器的结构不变

**oracle案例**

对于特征图$f \in \mathbb{R}^{hw \times d}$, vanilla classifier $C \in \mathbb{R}^{n \times d}$, gt标签$y_* \in \mathbb{R}^{n \times hw}$, 首先获得类别原型$C_y$

<img src="论文阅读记录-周报.assets/image-20230809092922757.png" alt="image-20230809092922757" style="zoom:80%;" />

oracle context-aware classifier $A_y \in \mathbb{R}^{n \times d}$计算为

<img src="论文阅读记录-周报.assets/image-20230809093105191.png" alt="image-20230809093105191" style="zoom:80%;" />

C为共享的分类器。预测$p_y$为

<img src="论文阅读记录-周报.assets/image-20230809093207513.png" alt="image-20230809093207513" style="zoom:80%;" />

$\eta$为沿通道维度的l2归一化，上式为计算余弦相似度，$\tau$将输出值范围从[-1,1]缩放到[-τ， τ]，实验中设为15。$p_y$可通过标准交叉熵进行优化

**学习上下文感知分类器**

测试时没有预测标签，因此通过预测p来代替真值$y_*$，得到估计的类原型$C_p$和 context-aware classifier$A_p \in \mathbb{R}^{n \times d}$, 最终得到预测$p_p$

与基础真值$y_*$提供的精确先验相比，p中包含的不确定性使得估计的分类原型Cp不如普遍共享的分类器C可靠，这可能使投影器θp倾向于忽略Cp。因此作者加入了KL散度$\mathcal{L}_{KL}$来正则化模型，从而鼓励通过模仿oracle情况$\mathcal{A}_{y}$的预测py来产生更具有有用信息的$\mathcal{A}_{p}$。换句话说，有用的知识是从$\mathcal{A}_{y}$提炼到$\mathcal{A}_{p}$的:

<img src="论文阅读记录-周报.assets/image-20230809094507752.png" alt="image-20230809094507752" style="zoom:80%;" />

$\mathcal{L}^{ce}$, $\mathcal{L}_y^{ce}$, $\mathcal{L}_p^{ce}$ 分别表示附加在$p$, $p_y$, $p_p$上的交叉熵损失。最终的损失函数为：

<img src="论文阅读记录-周报.assets/image-20230809094607064.png" alt="image-20230809094607064" style="zoom:80%;" />

**Entropy-aware蒸馏**

在Kl蒸馏过程中，信息量大的软目标的影响可能会被信息量小的软目标所淹没，从而导致较差的性能。根据信息水平调整各要素的贡献有利于知识的传递。在信息论中，熵H衡量的是一个变量的“信息量”。因此，对于预测$p_y$上的每个像素i，

<img src="论文阅读记录-周报.assets/image-20230809095518487.png" alt="image-20230809095518487" style="zoom:80%;" />

σ表示Softmax操作。通过引入熵掩模H∈R[hw]，KL更新为

<img src="论文阅读记录-周报.assets/image-20230809100017786.png" alt="image-20230809100017786" style="zoom:80%;" />

此外，在语义分割中，通常在一幅图像中存在多个类别，因此传播的信息仍然可能偏向大多数类别。为了解决这一问题，对不同类别的蒸馏损失进行了独立计算。最后，KL表示为:

<img src="论文阅读记录-周报.assets/image-20230809100149577.png" alt="image-20230809100149577" style="zoom:80%;" />

其中二进制掩码Mk = (y == k)表示存在第k个类。

**conclusion**

**优点**：引入了真值和预测值来计算类中心，使得分类器能够实现上下文感知。

**缺点**：分类器仍旧是参数化的，不能够优化特征的生成空间。而且也没有考虑到类内方差

### ECENet (ICCV 2023)

**Boosting Semantic Segmentation from the Perspective of Explicit Class Embedding**

**why**

出发点：基于类掩码适当地生成更显式和有意义的类嵌入

以前的：类嵌入被随机初始化并传递给解码器与特征映射交互，然后使用它来获得最终的分割掩码，这里的类嵌入最初被定义为隐式和无意义的，这意味着许多空间先验知识被忽略和丢失。

**what**

1，逆转了一般的解码过程，它偏离了随机初始化嵌入。本文的类嵌入总是显式的和有意义的。这是首次尝试揭示分割掩码和类嵌入之间的相关性，并探索两者之间可能的反向信息流。

2，在此基础上提出了一种新的网络ECENet，该网络由特征重构(FR)、显式类提取(ECE)、语义关注和更新(SAU)组成，并被证明是有效和高效的

**how**

<img src="论文阅读记录-周报.assets/image-20230811161711597.png" alt="image-20230811161711597" style="zoom:80%;" />

**总体架构**：backbone提取到的特征经过FR模块得到重构特征。然后从最后一个特征中提取显示类嵌入，前一阶段的特征与类嵌入相互作用，并逐渐传递更高层次的语义。掩码是注意力机制的副产品，用来增强类嵌入。最后，利用ghost feature和pixel shuffle对增强的多阶段特征进行上采样。然后将所有的特征连接在一起，通过1x1卷积得到最终的预测。对最终的类嵌入应用线性变换，然后进行Softmax激活，以获得类概率预测。然后，它与掩码相乘，并添加以增强最终的预测。

整体的损失函数为![image-20230811162932657](论文阅读记录-周报.assets/image-20230811162932657.png)

$\mathcal{L}_{cls}$监督最终的预测图，为交叉熵损失，$\mathcal{L}_{mask}$监督掩码，为focal loss和dice loss， $\mathcal{L}_{div}$应用于每个阶段的“多样化”分支特征

![image-20230811163845159](论文阅读记录-周报.assets/image-20230811163845159.png)

**Feature reconstruction (FR)**：（主要遵循ghostnet）特征映射中的多样性和冗余是成功网络的一个重要特征。提出特征重建(FR)，来有目的地控制特征映射的多样性和冗余。首先使用1x1卷积提取它们，旨在减少通道。提出了另一个多样化分支，该分支通过对特征中的每个固有特征进行简单廉价的线性运算来实现。然而，作者认为这种变换是不可控的，因此使用SE模块对通道进行增强。这里作者添加了 $\mathcal{L}_{div}$，确保每个像素被唯一覆盖。

（作者认为，在密集预测任务中，每个像素都应该被注意到，因此使每个特征图切片唯一是合理的。这里目前不太理解，估计要看下ghostnet）

<img src="论文阅读记录-周报.assets/image-20230811170426556.png" alt="image-20230811170426556" style="zoom:80%;" />

**Explicit class extraction (ECE)**：每个预测掩模片（slice）上的准确区域成为每个类别最自然的描述。通过使用预测掩码来获得显式定义的类嵌入。首先经过两个1*1卷积获得预测掩码，<img src="论文阅读记录-周报.assets/image-20230811171103393.png" alt="image-20230811171103393" style="zoom:80%;" />

然后对预测掩码进行池化与线性投影得到显式类嵌入，<img src="论文阅读记录-周报.assets/image-20230811171420213.png" alt="image-20230811171420213" style="zoom:80%;" />

<img src="论文阅读记录-周报.assets/image-20230811171536377.png" alt="image-20230811171536377" style="zoom:80%;" />

 **Semantics attention & updater (SAU)**：用于图像特征和显式类嵌入之间的交互，以及一个更新头，使用新获得的类表示刷新类表示。具体来说，Q为图像特征，k和v为类嵌入，

<img src="论文阅读记录-周报.assets/image-20230811171653847.png" alt="image-20230811171653847" style="zoom:80%;" />

同时$S(Q, K)$作为新的掩码$Mask(X_{i−1}, G)$用以更新类嵌入 :

<img src="论文阅读记录-周报.assets/image-20230811172430304.png" alt="image-20230811172430304" style="zoom:80%;" />

然后基于门控机制，将新的类嵌入与以前的表示进行融合，

<img src="论文阅读记录-周报.assets/image-20230811172605489.png" alt="image-20230811172605489" style="zoom:80%;" />

<img src="论文阅读记录-周报.assets/image-20230811172741387.png" alt="image-20230811172741387" style="zoom:80%;" />

**conclusion**

**优点**：使用显示类嵌入。随机初始化的类嵌入是隐式的，会忽略内容和空间先验

**缺点**：这个架构的话，显示类嵌入的获得描述过于粗糙。不太清楚具体怎么实现的。此外，初始类嵌入的准确性会严重影响最终结果的准确性。

### SegVIT (NIPS 2022)

**Segvit: Semantic segmentation with plain vision transformers**

**why**



**what**



**how**



**conclusion**

### SegVITv2 (ARXIV 2306)

**SegViTv2: Exploring Efficient and Continual Semantic Segmentation with Plain Vision Transformers**

**why**



**what**



**how**



**conclusion**

### SegNext (NIPS 2022)

**SegNeXt: Rethinking Convolutional Attention Design for Semantic Segmentation**

**why**

出发点：卷积注意比自注意机制更有效地编码上下文信息

以前的：transformer模型由于自注意机制在语义分割领域占据主导地位

**what**

1，确定了一个好的语义分割模型应该拥有的特性，并提出了一种新的定制网络架构，称为SegNeXt，它通过多尺度卷积特征唤起空间注意力。

1）一个强大的骨干网络作为编码器。2）多尺度信息交互。3）空间注意。空间注意力允许模型通过对semantic region内的area进行优先排序来进行分割。4）计算复杂度低。

2，本文表明，具有简单和廉价卷积的编码器仍然可以比视觉变压器表现更好，特别是在处理对象细节时，并且需要更少的计算成本。

**how**

<img src="论文阅读记录-周报.assets/image-20230811142827823.png" alt="image-20230811142827823" style="zoom:80%;" />

本文主要根据多尺度卷积注意(MSCA)模块来构造编码器。MSCA包含三个部分:用于聚合局部信息的深度卷积，用于捕获多尺度上下文的多分支深度卷积，以及用于模拟不同通道之间关系的1 × 1卷积。将1 × 1卷积的输出作为注意力权重，直接对MSCA的输入进行重加权。

<img src="论文阅读记录-周报.assets/image-20230811145419852.png" alt="image-20230811145419852" style="zoom:80%;" />

DW-Conv表示深度卷积（5x5），scale: i=0表示恒等连接，1，2, 3表示核大小为7,11,21的深度卷积。这里使用两个条形卷积来近似，1是因为条形卷积比较轻量，2是分割场景中存在一些条状物体，条形卷积可以作为网格卷积的补充，有助于提取条形特征。⊗是元素级的矩阵乘法运算（点乘）。

作者提出的编码器命名为MSCAN，并具有四个size（ MSCAN-T, MSCAN-S, MSCAN-B, MSCAN-L）

<img src="论文阅读记录-周报.assets/image-20230811142855735.png" alt="image-20230811142855735" style="zoom:80%;" />

作者研究了三种解码器结构，（a）为SegFormer采用的mlp解码器，（b）为cnn模型采用的基于重型解码器头，（c）为segnext采用的结构。汇总了最后三个阶段的特征，并使用轻量级的Hamburger进一步建模全局上下文

**conclusion**

**优点**：方法比较简单，卷积注意的思想可以实现空间维度和通道维度的自适应，比标准卷积和自注意更加有效

**缺点**：貌似是先空间卷积再通道卷积从而产生注意权重。有无可能会产生注意冲突的问题？基于通道轴向化（CAA）产生注意权重是否会更好

### 7 CoCs（ICLR2023 oral)

**Image as Set of Points** [paper](ICLR/Image as Set of Points.pdf)

**why**

出发点：将图像视为一组无组织的点，并通过简化的聚类算法提取特征

以前的：基于卷积或ViTs提取特征

**what**

1，将图像视为一组数据点，并将所有数据点分组为簇。在每个聚类中，我们将点聚集成一个中心，然后自适应地将中心点分配给所有的点。具体来说，将每个像素视为具有颜色和位置信息的5维数据点，从而把图像转换为一组点云，并利用点云分析的方法用于图像视觉表示学习。这架起了图像和点云表示的桥梁，显示出强大的泛化能力，并为多模态的轻松融合提供了可能性。并且上下文聚类处理为coc提供了令人满意的可解释性

2，引入了一种简化的聚类方法，将点分组成簇。据我们所知，我们是第一个为一般视觉表示引入聚类方法并使其发挥作用的人。

3，新设计本质上不同于ConvNets或vit，但继承了ConvNets的分层表示和vit的metaformer 框架。

**how**

![image-20230821113442866](论文阅读记录-周报.assets/image-20230821113442866.png)

见上图，给定输入图像$I \in \mathbb{R}^{3 \times w \times h}$，首先用每个像素的二维坐标$[\frac{i}{w}-0.5, \frac{j}{h}-0.5]$来增强图像, 将增强图像转换为点的集合(即像素)$P \in \mathbb{R}^{5 \times N}$, 每个点同时包含特征(颜色)和位置(坐标)信息; 因此，点集可能是无序和无组织的。

**points reducer**：为了减少点的数量，在空间中均匀地选择一些锚点，并通过线性投影将最近的k个点连接和融合。如果所有点按顺序排列并且k适当设置(即4和9)，则可以通过卷积操作实现这种减少（比如vit中的patch转为特征）

**上下文聚类**：总体上，首先将特征点分组成簇; 然后，将每个簇中的特征点进行聚合（aggregate），然后再进行回调（dispatch）

1，给定一组特征点p，根据相似度将所有特征点分成几组，每个点单独分配给一个聚类。具体来说，在空间中均匀地提出c个中心，并通过平均其k个最近点来计算中心特征。然后，计算p和中心点集之间的余弦相似矩阵s，将每个点分配给最相似的中心，得到c个簇。

2，根据与中心点的相似度动态聚集该聚类中的所有点（共m个点）。

![image-20230821142210146](论文阅读记录-周报.assets/image-20230821142210146.png)

α和β是可学习的标量，用于缩放和移动相似性，sig(·)是一个sigmoid函数，用于将相似性重新缩放到(0,1)。vc是value空间的值中心。Softmax不被考虑，因为这些点并不相互矛盾。为了数值稳定性，在Eq. 1中加入了值中心vc，并进一步强调了局域性。为了控制大小，聚合特征通过因子C归一化。

这一步就是通过计算相似度将簇中的点加权整合得到中心点。

3，根据相似性自适应地将聚合特征g分配到集群中的每个点，通过这样做，点之间可以相互通信，并共享集群中所有点的特征。此外，参考了多头设计，FC可以用来拼接多头的输出

![image-20230821142755778](论文阅读记录-周报.assets/image-20230821142755778.png)

![image-20230821113642200](论文阅读记录-周报.assets/image-20230821113642200-1692598938916-1.png)

**架构初始化**：每个阶段逐步减少16、4、4和4倍的点数（即下采样1/4,1/2,1/2）。在第一阶段为选定的锚点考虑16个最近的邻居，在其余阶段选择它们的9个最近的邻居。（锚点用来下采样）此外，为了提高计算效率，引入区域划分，将点分成几个局部区域，在局部计算相似度（如swin）。

额外的讨论：

1，聚类中心固定还是动态。传统的聚类算法和超像素技术都是迭代地更新中心直到收敛。然而，当集群被用作每个构建块中的关键组件时，这将导致过高的计算成本。因此在上下文聚类中，采取固定中心，可以将其视为准确性和速度之间的折衷

2，cluster重叠还是非重叠：本文想证明简单而传统的算法可以作为通用的主干，因此坚持传统的聚类方法(非重叠聚类)。

**conclusion**

优点：1，有利于处理离散数据，上下文聚类不要求图像像素处于连续空间中。比如对于掩码图像和不规则图像，传统的ConvNets或ViTs要求图像填充白色像素。而上下文聚类将遮罩或不规则图像解释为离散点，从而实现聚类。

缺点：1，上下文聚类在分类上比较灵活（取所有点的平均值），但对于检测和分割等下游密集预测任务，需要在每个阶段之后按位置重新排列输出点。因此需要设计新的检测和分割头。

2，区域划分如何删除。区域划分会引入有用的归纳偏差，如局部性，但牺牲了对全局相互作用建模的能力。作者进行了实验，不进行区域划分结果有提升，但是训练时间和记忆需求显著增加。

3，如何设计更好的策略来妥协准确性和速度。比如作者采用的固定聚类中心和非重叠聚类